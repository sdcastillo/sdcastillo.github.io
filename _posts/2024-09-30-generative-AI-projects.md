---
title: "Generative AI Projects"
layout: post
excerpt: ""
categories:
  - AI
  - LLM
  - Data
tags:
last_modified_at: 2024-09-30T12:43:31-05:00
---

This podcast was created from google's notebook ML, feeding in my PDF of a data analysis project:

<iframe width="560" height="315" src="https://www.youtube.com/embed/n3SxfyAPQjE?si=pEOCTXMEKyu9LG-2" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

This was as well:

<iframe width="560" height="315" src="https://www.youtube.com/embed/Htiebwa8I00?si=vol__vFy_bKpSxmL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

The use of machine learning and regression models can accurately predict bike sharing demand, and that AI can be trained to understand and use these models effectively.
ü§ñ
00:00 Chat with a document on AWS Bedrock to summarize a complex 18-page technical piece of writing.
üìù
01:35 The document examines data on bike sharing demand and explores modeling approaches to predict the number of bike rentals per hour, evaluating various regression models and identifying key factors influencing demand.

ü§ñ AMAZING!

All right, the implications to this ability of an LLM to comprehend a machine learning paper are amazing.  Consider what will happen when I give Claude all the machine learning code....  this is a step ahead of AutoML.  More than AI Feature Engineering.  Is this supervised learning, or unsupervised?  

‚ñ∂Ô∏è If you enjoy this video, please like it and share it.    
‚ñ∂Ô∏è Don't forget to subscribe to this channel for more updates.    
‚ñ∂Ô∏è Subscribe now:    YouTube.com/@predictiveanalyst  

<iframe width="560" height="315" src="https://www.youtube.com/embed/4aXw2bg1TSc?si=srysUpLT98WFyAUa" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

When the Omni update was released, Open AI made a huge update to their chat, and although it was already quite effective now it feels even more emotional like I‚Äôm texting a friend.  

This clip shows me using an API for chat GPt4(o) that is called FreedomGPT which is a project to make LLMs available to all.  Now I purchased and use the official app.

The Open AI that I use for chat GPT has model selection for 3.5, 4, and 4(O) though you max out the request limit.   Using 3.5 for basic tasks because this is efficient.

You can ask it more open-ended questions and still get good answers. Although I would say it still suffers from the formatting issues ‚Äî it‚Äôs understandable. It will give you more information than you need it to as in this example, when I asked it to fill in a few sentences, it returned an entire document.  This is still the same problem that we humans face which is how do you effectively select the information that‚Äôs important.  Google has also released many AI products this week, though that‚Äôs outside the scope of this video.

<iframe width="560" height="315" src="https://www.youtube.com/embed/3H1-ozD6zsM?si=GpY0cWYz9eqlL23U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
