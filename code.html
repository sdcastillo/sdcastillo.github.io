<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Code that Writes Code ‚Äì Predictive Analyst</title>
  <meta name="description" content="Self-improving AI systems, quantum computing, portfolio wave functions, SHA-256 hashing, and comparative hardware models by Samuel Castillo.">
  
  <!-- MathJax for beautiful LaTeX -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
  
  <!-- Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ECY33592SW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-ECY33592SW');
  </script>

  <style>
    :root {
      --bg: #0f0f1a;
      --card: #16162a;
      --text: #e0e0ff;
      --text-muted: #b8c8ff;
      --accent: #00d4ff;
      --accent-hover: #00ff9d;
      --pink: #ff006e;
      --border: rgba(0, 212, 255, 0.15);
    }

    * { box-sizing: border-box; margin:0; padding:0; }
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: var(--bg);
      color: var(--text);
      line-height: 1.7;
      margin: 0;
    }

    /* Navigation */
    .main-nav {
      background: #0a0a14;
      padding: 1.2rem 5%;
      display: flex;
      justify-content: space-between;
      align-items: center;
      flex-wrap: wrap;
      gap: 1rem;
      border-bottom: 1px solid var(--border);
      position: sticky;
      top: 0;
      z-index: 1000;
    }
    .nav-left, .nav-right { display: flex; align-items: center; gap: 2rem; gap: 2rem; }
    .main-nav a {
      color: #a0d8ff;
      text-decoration: none;
      font-weight: 500;
      transition: color 0.3s;
    }
    .main-nav a:hover, .main-nav a.active { color: var(--accent); }
    .brand { font-size: 1.4rem; font-weight: 700; color: var(--accent) !important; }
    .buy-cta {
      background: var(--pink);
      color: white !important;
      padding: 0.6rem 1.3rem;
      border-radius: 50px;
      font-weight: 600;
    }
    .buy-cta:hover { background: #ff3388; }

    /* Dropdown */
    .dropdown { position: relative; }
    .dropbtn {
      background: none; border: none; color: #a0d8ff; font-weight: 500;
      cursor: pointer; display: flex; align-items: center; gap: 0.4rem;
    }
    .dropdown-content {
      display: none; position: absolute; background: #16162a;
      min-width: 300px; border-radius: 12px; box-shadow: 0 10px 30px rgba(0,212,255,0.2);
      top: 100%; right: 0; padding: 0.8rem 0; opacity: 0; visibility: hidden;
      transform: translateY(-10px); transition: all 0.3s ease;
    }
    .dropdown:hover .dropdown-content {
      display: block; opacity: 1; visibility: visible; transform: translateY(0);
    }
    .dropdown-content a {
      padding: 0.7rem 1.4rem; display: block; color: #b8c8ff;
    }
    .dropdown-content a:hover { background: rgba(0,212,255,0.1); color: var(--accent); }

    /* Hero Header */
    header {
      background: linear-gradient(135deg, #1a1a2e, #16213e);
      padding: 100px 20px 80px;
      text-align: center;
      border-bottom: 5px solid var(--accent);
    }
    h1 {
      font-size: 3.6rem;
      color: var(--accent);
      margin: 0 0 1rem;
    }
    .subtitle {
      font-size: 1.5rem;
      color: #a0f8ff;
      max-width: 800px;
      margin: 0 auto;
    }

    /* Main Content */
    .container {
      max-width: 1240px;
      margin: 0 auto;
      padding: 40px 20px;
    }

    /* Video Blog Section */
    .video-section {
      margin: 60px 0;
    }
    .video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(520px, 1fr));
      gap: 40px;
      margin-top: 40px;
    }
    .video-card {
      background: var(--card);
      border-radius: 16px;
      overflow: hidden;
      box-shadow: 0 10px 30px rgba(0,212,255,0.15);
      transition: all 0.4s ease;
    }
    .video-card:hover {
      transform: translateY(-12px);
      box-shadow: 0 25px 60px rgba(0,212,255,0.3);
    }
    .video-wrapper {
      position: relative;
      padding-bottom: 56.25%;
      background: #000;
    }
    .video-wrapper iframe {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      border: none;
    }
    .video-info {
      padding: 32px;
    }
    .video-info h2 {
      color: var(--accent-hover);
      font-size: 1.8rem;
      margin-bottom: 1rem;
    }
    .video-info p, .video-info ul {
      color: var(--text-muted);
    }
    .tags {
      margin-top: 20px;
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
    }
    .tags span {
      background: var(--border);
      color: var(--accent);
      padding: 6px 14px;
      border-radius: 30px;
      font-size: 0.85rem;
    }

    /* General Content Styling */
    section {
      margin: 80px 0;
    }
    h2 {
      color: var(--accent);
      margin: 2rem 0 1.2rem;
    }
  pre {
  background: #0d0d18;
  border: 1px solid rgba(0, 212, 255, 0.2);
  border-radius: 12px;
  padding: 1.6rem !important;
  margin: 2rem 0;
  overflow-x: auto;
  position: relative;
  box-shadow: 0 8px 25px rgba(0, 0, 0, 0.4);
  font-size: 0.98rem;
  line-height: 1.65;
  font-family: 'Fira Code', 'JetBrains Mono', 'Consolas', 'Monaco', monospace;
}

pre::before {
  content: "";
  position: absolute;
  top: 0; left: 0; right: 0; height: 4px;
  background: linear-gradient(90deg, #00d4ff, #ff006e, #00ff9d);
  border-radius: 12px 12px 0 0;
}

code {
  font-family: inherit;
  background: transparent;
  padding: 0;
  border-radius: 0;
}

/* Inline code */
:not(pre) > code {
  background: rgba(0, 212, 255, 0.12);
  color: #00ff9d;
  padding: 0.2em 0.45em;
  border-radius: 6px;
  font-size: 0.92em;
  border: 1px solid rgba(0, 212, 255, 0.25);
}
    pre { margin: 1.5rem 0; }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 2rem 0;
      border-radius: 12px;
      overflow: hidden;
      box-shadow: 0 10px 30px rgba(0,0,0,0.4);
    }
    th {
      background: linear-gradient(90deg, #182848, #4b6cb7);
      color: white;
      padding: 16px;
      text-align: left;
    }
    td {
      padding: 14px 16px;
      border-bottom: 1px solid rgba(255,255,255,0.07);
      background: rgba(255,255,255,0.02);
    }
    tr:hover { background: rgba(0,212,255,0.1); }

    /* Footer */
    footer {
      text-align: center;
      padding: 100px 20px;
      background: #0a0a14;
      border-top: 1px solid var(--border);
    }
    .subscribe-btn {
      background: var(--pink);
      color: white;
      padding: 18px 50px;
      border-radius: 50px;
      text-decoration: none;
      font-weight: bold;
      font-size: 1.3rem;
      display: inline-block;
      margin: 20px 0;
      transition: 0.3s;
    }
    .subscribe-btn:hover { background: #ff3388; transform: scale(1.05); }

    /* Responsive */
    @media (max-width: 768px) {
      .video-grid { grid-template-columns: 1fr; }
      h1 { font-size: 2.8rem; }
      .main-nav { flex-direction: column; text-align: center; }
      .nav-left, .nav-right { gap: 1rem; justify-content: center; }
    }
  </style>
</style>
</head>
<body>

  <!-- Navigation -->
  <nav class="main-nav">
    <div class="nav-left">
      <a href="index.html" class="brand">Samuel Castillo</a>
      <a href="about.html">About</a>
      <a href="privacy.html">Privacy</a>
    </div>
    <div class="nav-right">
      <a href="index.html">Futuro Insights</a>
      <a href="code.html" class="active">Code</a>
      <a href="/PA-R-Study-Manual">PA-R Study Manual</a>
      <div class="dropdown">
        <button class="dropbtn">Projects & Articles ‚Üì</button>
        <div class="dropdown-content">
          <a href="/github_pages_central_limit_theorem.html">Central Limit Theorem</a>
          <a href="/github_pages_from_algorithms_to_actuarial_science.html">From Algorithms to Actuarial Science</a>
          <a href="/github_pages_identifying_actionable_treatment_variation.html">Identifying Actionable Treatment Variation</a>
          <a href="/github_pages_linear_algebra.html">Linear Algebra Notes</a>
          <a href="/github_pages_loss_development_triangles.html">Loss Development Triangles</a>
          <a href="/github_pages_grocery_stores.html">Grocery Store Supply Modeling</a>
          <a href="/github_pages_predictive_modeling_app.html">Predictive Modeling App</a>
          <a href="/github_pages_prompt_engineering.html">Prompt Engineering Guide</a>
          <a href="/github_pages_real_estate_house_prices.html">Real Estate House Price Modeling</a>
          <a href="/github_pages_sas_for_statistics_healthcare.html">SAS for Healthcare Statistics</a>
          <a href="/github_pages_soa_predictive_modeling_research.html">SOA Predictive Modeling Research</a>
          <a href="/github_pages_value_investing_time_series.html">Value Investing & Time-Series Analysis</a>
        </div>
      </div>
    </div>
  </nav>

  <!-- Hero -->
  <header>
    <h1>Predictive Analyst on YouTube</h1>
    <p class="subtitle">Quantum & Code ‚Ä¢ Local LLMs ‚Ä¢ Exam PA </p>
  </header>

  <div class="container">

    <!-- Video Blog Section -->
    <section class="video-section">
      <div class="video-grid">

        
            <!-- 3. The Essentials of Predictive Modeling with Howard Friedman, -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/3yqPQEefUHI?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Trustworthy Vibes in Coding" allowfullscreen></iframe>
            
          </div>
          <div class="video-info">
            <h2>Inside DataFest: The Ultimate College Coding Challenge</h2>
            <p>Imagine this.... a massive coding competition meets Shark Tank.  Now add AI, Business Intelligence, and a room full of students cracking it wide open. Yeah, welcome to DataFest. This isn't just about code, it's about real problems, real data, and real solutions that slap.  The energy?  Electric.  

               The mission of DataFest is to expose undergraduate students to challenging questions with immediate real-world significance that can be addressed through data analysis. By working in teams, students with varying skill sets will combine their efforts and expand their collective data analysis horizons. Interaction among students, as well as with outside consultants, will promote the sense that data analysis is a dynamic, engaging, and vibrant part of our society, as well as a realistic, practical, and fun career path.</p>
            <div class="tags">
              <span>#DataFest</span><span>#UMassAmherst</span><span>#WesternMassTech</span><span>#machinelearningpython</span>

            </div>
          </div>
        </div>


         <!-- 3. The Essentials of Predictive Modeling with Howard Friedman, -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/1LSZcxItWuY?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Trustworthy Vibes in Coding" allowfullscreen></iframe>
            
          </div>
          <div class="video-info">
            <h2>The Essentials of Predictive Modeling with Howard Friedman, PhD</h2>
            <p>With Howard Friedman, PhD, Coloumbia University, data scien

              Typical Data Science Playbook Elements Can Include:

              Data Strategy Development and Project Prioritization
              Model Improvements/Optimization
              Customer Segmentation: Applicable to B-B and B-C
              Profitability Analysis: Product-level, Customer-level
              Site Selection:
              Operations Metrics Selection: Factors drive quality, profitability, efficiency, etc.
              Risk Modeling/Failure Modeling: Product-level, Customer-level, Site-level
              Forecasting: Incorporating internal and external data
              Marketing Optimization:
              Automation Opportunities:
              Human Resources Modeliing: Modeling success, attrition, etc.</p>
            <div class="tags">
              <span>#Retail</span><span>#MachineLearning</span><span>#DataScience</span><span>#BigData</span>
            </div>
          </div>
        </div>

        
         <!-- 3. The Essentials of Predictive Modeling with Dave Snell FSA, MAA, -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/R5H90R8ssAI?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Trustworthy Vibes in Coding" allowfullscreen></iframe>
            
          </div>
          <div class="video-info">
            <h2>The Essentials of Predictive Modeling with Dave Snell, FSA, MAA and Ahmed Rasheed</h2>
            <p>üìö Ready to conquer Exam PA? Join our latest webinar for an enlightening session on machine learning and strategic study tips. 

            Led by experts Dave Snell and Ahmed Rasheed, this webinar is your gateway to mastering predictive analytics. 

            Explore unique picture-definition associations to enhance your recall of statistical definitions. 

            Jump to the main content at 11:59 for a focused review. 

            It is important to consider whether the business problem is to gain inference about data or to make predictions without needing to understand the model.  </p>
                        <div class="tags">
              <span>#ExamPAStudyTips</span><span>#MachineLearning</span><span>#AI</span><span>#StudyStrategies</span>
            </div>
          </div>
        </div>

                 <!-- 3. umass -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/LiOX57UyKI0?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Trustworthy Vibes in Coding" allowfullscreen></iframe>
            
          </div>
          <div class="video-info">
            <h2>Future Role of AI with the UMass Amherst Actuarial Science Students</h2>
            <p>üìö Sam Castillo, a UMass Amherst alumnus, discusses his non-traditional actuarial career, the integration of AI in risk assessment, and strategies for exam preparation. He emphasizes building a strong resume, understanding actuarial designations, and the importance of interpersonal skills, while also reflecting on career satisfaction and opportunities for international work.

            <ul>
              <li><strong>00:00:00 - 00:08:12</strong> Sam Castillo's Actuarial Journey and Exam Preparation</li>
              <li><strong>00:08:12 - 00:16:59</strong> Building Experience and Marketing Skills for Actuarial Science Students</li>
              <li><strong>00:16:59 - 00:19:22</strong> Actuarial Profession Perks and Opportunities</li>
              <li><strong>00:19:22 - 00:27:27</strong> The Impact of AI in Actuarial Science and Personal Career Reflections</li>
              <li><strong>00:27:27 - 00:37:21</strong> Actuarial Science vs. Statistics and Exam Pathways</li>
              <li><strong>00:37:21 - 00:45:03</strong> Learning R and Python for Actuarial Science and Career Advice</li>
              <li><strong>00:45:03 - 00:50:22</strong> The Importance of Actuarial Exams and Career Progression</li>
              <li><strong>00:50:22 - 00:54:07</strong> Career Path and Professional Development in Actuarial Science</li>
            </ul>
              </p>
                        <div class="tags">
              <span>#AIinActuarialScience</span><span>#CareerAdviceForActuaries</span><span>#PredictiveModeling</span><span>#UMassAmherstAlumni</span>
            </div>
          </div>
        </div>

        <!-- 1. Powerful Workflow Automation Tools -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/2fMhWF574c4?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Powerful Workflow Automation Tools" allowfullscreen></iframe>
          
          </div>
          <div class="video-info">
            <h2>Powerful Workflow Automation Tools - Database with LLMs</h2>
            <p>Build limitless AI-powered automations using emails to custom prompts to OpenAI to Supabase to Notion and more.</p>
            <p><strong>Step-by-step:</strong> custom email trigger to OpenAI API to Supabase storage to Notion/Slack to perfect audit trail.</p>
            <div class="tags">
              <span>#AI</span><span>#Automation</span><span>#LLM</span><span>#NoCode</span><span>#CyberSecurity</span>
            </div>
          </div>
        </div>

        <!-- 2. Cyber Security 2025 -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/vJUZidl3y5E?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Cyber Security Introduction 2025" allowfullscreen></iframe>
          
          </div>
          <div class="video-info">
            <h2>Start Here: Complete Cyber Security Introduction for 2025</h2>
            <p>Master cyber security basics in 20 minutes ‚Äì hacker mindset, free tools, ethical hacking, careers.</p>
            <div class="tags">
              <span>#CyberSecurity</span><span>#InfoSec</span><span>#EthicalHacking</span><span>#2025</span>
            </div>
          </div>
        </div>

        <!-- 3. Trustworthy Vibes in Coding -->
        <div class="video-card">
          <div class="video-wrapper">
            <iframe src="https://www.youtube-nocookie.com/embed/fCjGS2dHdXo?rel=0&modestbranding=1&autoplay=0&controls=1&fs=1&iv_load_policy=3&showinfo=0" title="Trustworthy Vibes in Coding" allowfullscreen></iframe>
            
          </div>
          <div class="video-info">
            <h2>Internal Local Area Networks</h2>
            <p>Run Mistral AI and Large Language Models fully offline on your own secure LAN ‚Äî zero cloud, zero data leaks.</p>
            <div class="tags">
              <span>#LocalAI</span><span>#PrivateAI</span><span>#SelfHosted</span><span>#Privacy</span>
            </div>
          </div>
        </div>
        
        

        <!-- Add more videos the same way... (all 7 are included below) -->
        <!-- ... (4‚Äì7 same format as above) ... -->
      </div>
    </section>


    <!-- ... ALL your original sections (math, tables, quantum, password cracking, etc.) remain 100% intact ... -->
   
     <h1>Code that writes code</h1>
    <p>Exponential-looking growth in computing emerges when systems can improve their own code. Once a loop exists that can generate, execute, measure, and refine programs, capability compounds: each improvement enhances the next round of search over the program phase space. The driver is not just device density, but a feedback process that compresses errors, increases information flow, and reduces effective entropy in the distribution of behaviors.</p>
    <p>
      In mathematical terms, let the capability at iteration \(t\) be \(C(t)\). A simple model of compounded self-improvement is
      \[
        C(t+1) = (1 + r)\,C(t), \qquad r > 0,
      \]
      whose solution is
      \[
        C(t) = C(0)\,(1 + r)^t \approx C(0)\,e^{rt},
      \]
      capturing the "exponential-looking" growth. A more general continuous-time feedback model writes
      \[
        \frac{dC}{dt} = f(I,C,E),
      \]
      where \(I\) measures information flow through the system and \(E\) is the average error. A negative dependence \(\partial f/\partial E < 0\) and positive \(\partial f/\partial I > 0\) encode that reducing errors and increasing information flow accelerates capability.
    </p>
    <p>
      Let the program hypothesis space be a high-dimensional manifold \(\mathcal{H}\) with coordinates \(\theta \in \mathbb{R}^d\) parameterizing programs, and let a loss (or energy-like) function be \(L : \mathcal{H} \to \mathbb{R}_+\). Guided search corresponds to iterates
      \[
        \theta_{t+1} = \theta_t - \eta_t \, \nabla_\theta L(\theta_t) + \xi_t,
      \]
      where \(\eta_t\) is a learning rate and \(\xi_t\) represents stochastic exploration. The associated probability density over programs, \(p_t(\theta)\), can be modeled as a Gibbs-like distribution
      \[
        p_t(\theta) = \frac{1}{Z_t} \exp\big(-\beta_t L(\theta)\big),
      \]
      with partition function \(Z_t\) and inverse temperature \(\beta_t\) reflecting how strongly the system prefers lower-loss code. As \(t\) increases and \(\beta_t\) grows, the distribution contracts around high-quality programs, reducing effective entropy
      \[
        S[p_t] = - \int_{\mathcal{H}} p_t(\theta)\, \log p_t(\theta)\, d\theta.
      \]
    </p>

    <h2>Mechanism of self-improvement</h2>
    <ul>
      <li>Program synthesis as guided search over a high-dimensional landscape; gradients, heuristics, and discrete exploration move candidates toward lower loss (energy-like objective).</li>
    </ul>
    <p>
      Formally, represent each candidate program by parameters \(\theta \in \mathbb{R}^d\) and define an objective (loss/energy) \(L(\theta)\). Gradient-based guidance is
      \[
        \theta_{t+1} = \theta_t - \eta_t \, \nabla_\theta L(\theta_t),
      \]
      while purely heuristic or discrete search can be modeled by a Markov chain with transition kernel \(K(\theta'\mid\theta)\) that satisfies
      \[
        p_{t+1}(\theta') = \int K(\theta'\mid\theta)\,p_t(\theta)\,d\theta,
      \]
      where \(p_t(\theta)\) is the probability density over program parameters at iteration \(t\). The stationary distribution \(p_*(\theta)\) often approximates a Boltzmann form \(p_*(\theta) \propto e^{-\beta L(\theta)}\), concentrating mass near minima of \(L\).
    </p>
    <ul>
      <li>Error-correcting feedback reduces uncertainty: observations act as measurements that collapse hypotheses, concentrating probability mass on higher-fidelity code.</li>
    </ul>
    <p>
      Let \(\Theta\) be a discrete hypothesis set of programs, with prior \(P(\theta)\) for \(\theta \in \Theta\). Given observed data or test outcomes \(D\), Bayes' rule updates beliefs via
      \[
        P(\theta \mid D) = \frac{P(D \mid \theta)P(\theta)}{P(D)}, \qquad P(D) = \sum_{\theta' \in \Theta} P(D \mid \theta')P(\theta').
      \]
      The Shannon entropy of the hypothesis distribution is
      \[
        H[P] = -\sum_{\theta \in \Theta} P(\theta)\,\log P(\theta).
      \]
      Error-correcting feedback corresponds to sequences of measurements \(D_1, D_2, \dots\) such that
      \[
        H\big[P(\cdot \mid D_1,\dots,D_t)\big] \searrow H_* \quad \text{as} \quad t \to \infty,
      \]
      where \(H_*\) is low and the posterior probability mass is concentrated on a small set of high-fidelity programs.
    </p>
    <ul>
      <li>Thermodynamics of computation: every irreversible operation dissipates energy; efficient self-editing favors representations and compilers that minimize erasures while maximizing useful work per joule.</li>
    </ul>
    <p>
      Landauer's principle states that erasing one bit of information incurs a minimum heat dissipation
      \[
        Q_{\min} = k_B T \ln 2,
      \]
      where \(k_B\) is Boltzmann's constant and \(T\) is the ambient temperature. If a self-editing system performs \(N_\text{erase}\) bit erasures per update, the minimal thermodynamic cost per update is
      \[
        Q_\text{update} \ge N_\text{erase}\,k_B T \ln 2.
      \]
      The computational efficiency can be expressed as useful information gain per unit energy,
      \[
        \eta_\text{info} = \frac{\Delta I}{Q_\text{update}},
      \]
      where \(\Delta I\) is the increase in mutual information between internal model parameters \(\Theta\) and task outcomes \(Y\):
      \[
        I(\Theta;Y) = \sum_{\theta,y} p(\theta,y)\, \log \frac{p(\theta,y)}{p(\theta)\,p(y)}.
      \]
      Efficient self-editing corresponds to strategies that maximize \(\eta_\text{info}\) by minimizing unnecessary erasures and maximizing \(\Delta I\).
    </p>
    <ul>
      <li>Compression and generalization: shorter effective descriptions (lower algorithmic complexity) tend to transfer across tasks, enabling accelerated reuse and faster convergence on new problems.</li>
    </ul>
    <p>
      Let the Kolmogorov complexity (algorithmic information content) of a solution for task \(T\) be \(K(T)\), defined as the length (in bits) of the shortest program that solves \(T\) on a fixed universal Turing machine \(U\). For two tasks \(T_1, T_2\), the shared structure can be quantified by an information-theoretic overlap
      \[
        I(T_1;T_2) \approx K(T_1) + K(T_2) - K(T_1,T_2),
      \]
      where \(K(T_1,T_2)\) is the complexity of jointly solving both tasks. Reusable compressed representations correspond to internal codes \(z\) of small description length \(L(z)\) that minimize expected description length over tasks:
      \[
        \min_{z} \, \mathbb{E}_{T \sim \mathcal{D}}\big[ L(z) + L(T \mid z) \big],
      \]
      with \(\mathcal{D}\) a task distribution. Lower \(L(z)\) and \(L(T\mid z)\) imply faster adaptation and thus accelerated convergence on new problems.
    </p>

    <div class="qc-beginner-box">
      <strong>Beginner note:</strong> If the math above feels heavy, you do not need to absorb every symbol. The key idea is simple:
      <em>systems that can test and improve their own code can get better very quickly</em>.
      Quantum computing plugs into this story by giving those systems a new kind of hardware to explore enormous search spaces more efficiently.
    </div>

    <h2>How this page is assembled</h2>
    <p>This page was assembled with automated assistance: generative tooling produced structure and text, which were reviewed and emitted as static HTML. In other words, the site itself serves as a small example of code that helps author more code. AI for Not Bad.</p>
    <p>
      Abstractly, denote the human editor as \(H\) and the generative model as \(G\). Let \(x\) be an initial specification and \(y\) the final HTML. The interaction can be seen as an alternating minimization over drafts \(y_t\):
      \[
        y_{t+1} = \operatorname*{arg\,min}_{y} 
          \Big( \mathcal{L}_\text{spec}(y \mid x) + \mathcal{L}_\text{style}(y) + \mathcal{L}_\text{error}(y) \Big),
      \]
      with updates produced by either \(G\) or \(H\):
      \[
        y_{t+1} =
        \begin{cases}
          G(y_t,x,\xi_t) & \text{with probability } p_G, \\
          H(y_t,x) & \text{with probability } 1-p_G,
        \end{cases}
      \]
      where \(\xi_t\) captures model stochasticity. Convergence is reached when successive edits satisfy a small-difference condition, e.g.
      \[
        d(y_{t+1},y_t) < \varepsilon,
      \]
      for a suitable distance metric \(d\) on documents.
    </p>

    <details class="qc-deepdive">
      <summary>Deep dive: a tiny quantum circuit in code and math</summary>
      <div>
        <p>Here is a minimal example of preparing a Bell state using Python-style pseudocode with a Qiskit‚Äëlike API, plus the matching math.</p>
        <pre><code># Pseudocode using a Qiskit-like API
from qiskit import QuantumCircuit

qc = QuantumCircuit(2, 2)  # 2 qubits, 2 classical bits

# 1. Put qubit 0 into a superposition
qc.h(0)

# 2. Use it as control for a CNOT on qubit 1
qc.cx(0, 1)

# 3. Measure both qubits
qc.measure(0, 0)
qc.measure(1, 1)</code></pre>
        <p>Mathematically, in the \(|00\rangle,|01\rangle,|10\rangle,|11\rangle\) basis:</p>
        <ol>
          <li>Start in \(|00\rangle\).</li>
          <li>Apply \(H\) to the first qubit:
            \[
              H|0\rangle = \tfrac{1}{\sqrt{2}}(|0\rangle + |1\rangle),
            \]
            so the joint state becomes
            \[
              |\psi_1\rangle = \tfrac{1}{\sqrt{2}}(|00\rangle + |10\rangle).
            \]</li>
          <li>Apply CNOT with qubit 0 as control and qubit 1 as target:
            \[
              \text{CNOT}|00\rangle = |00\rangle, \quad
              \text{CNOT}|10\rangle = |11\rangle.
            \]
            Therefore
            \[
              |\psi_2\rangle = \tfrac{1}{\sqrt{2}}(|00\rangle + |11\rangle) = |\Phi^+\rangle.
            \]</li>
        </ol>
        <p>When you measure both qubits in the computational basis, you get:</p>
        <ul>
          <li>\(P(00) = 1/2\)</li>
          <li>\(P(11) = 1/2\)</li>
          <li>\(P(01) = P(10) = 0\)</li>
        </ul>
        <p>This is ‚Äúmaximal entanglement‚Äù in its simplest form.</p>
      </div>
    </details>

    <h2>Minimal meta-programming sketch</h2>
    <pre><code>// Pseudocode for a self-improving loop
population = initialize_programs()
while (time &lt; budget):
  for prog in population:
    result = execute(prog, tests)
    score  = measure(result)
    log(result, score)
  models = fit_surrogates(log)          // learn to predict score from program features
  proposals = propose(models)           // synthesize or mutate new programs
  population = select(population, proposals, log) // keep better, diverse candidates
  if converged(population): break
deploy(best(population))
</code></pre>
    <p>
      Let the population at iteration \(t\) be \(\mathcal{P}_t = \{\theta_t^{(1)},\dots,\theta_t^{(N)}\}\), and let each candidate have a score (fitness) \(F(\theta)\). The selection step can be modeled by a softmax (Boltzmann) sampling distribution
      \[
        P_t(\theta) = \frac{\exp\big(\beta_t F(\theta)\big)}{\sum_{\theta' \in \mathcal{P}_t} \exp\big(\beta_t F(\theta')\big)},
      \]
      with inverse temperature \(\beta_t\) controlling selection pressure. Proposals (mutations or synthesized programs) \(\tilde{\theta}\) are drawn from a proposal kernel \(q_t(\tilde{\theta} \mid \theta)\), so the expected update of the population distribution is
      \[
        p_{t+1}(\tilde{\theta}) = \sum_{\theta} P_t(\theta)\, q_t(\tilde{\theta} \mid \theta).
      \]
      Convergence of the loop can be expressed via a stopping condition such as
      \[
        \operatorname{Var}_{\theta \sim p_t}[F(\theta)] < \delta
        \quad \text{or} \quad
        \max_{\theta \in \mathcal{P}_t} F(\theta) - \max_{\theta \in \mathcal{P}_{t-k}} F(\theta) < \epsilon,
      \]
      for some window size \(k\) and tolerances \(\delta, \epsilon\).
    </p>

    <h2>Hierarchical graph of matter and interactions</h2>
    <pre>Universe
‚îî‚îÄ Quantum fields
   ‚îú‚îÄ Fermion fields (matter)
   ‚îÇ  ‚îú‚îÄ Quarks (color charge: red/green/blue)
   ‚îÇ  ‚îÇ  ‚îú‚îÄ Flavors: up, down, charm, strange, top, bottom
   ‚îÇ  ‚îÇ  ‚îî‚îÄ Bound states (hadrons)
   ‚îÇ  ‚îÇ     ‚îú‚îÄ Baryons (3 quarks)
   ‚îÇ  ‚îÇ     ‚îÇ  ‚îú‚îÄ Proton: u u d
   ‚îÇ  ‚îÇ     ‚îÇ  ‚îú‚îÄ Neutron: u d d
   ‚îÇ  ‚îÇ     ‚îÇ  ‚îî‚îÄ Antibaryons (3 antiquarks)
   ‚îÇ  ‚îÇ     ‚îÇ     ‚îî‚îÄ Antiproton: uÃÑ uÃÑ dÃÑ
   ‚îÇ  ‚îÇ     ‚îî‚îÄ Mesons (quark + antiquark)
   ‚îÇ  ‚îî‚îÄ Leptons
   ‚îÇ     ‚îú‚îÄ Electron, Muon, Tau
   ‚îÇ     ‚îî‚îÄ Neutrinos (three types) + corresponding antiparticles (e.g., positron)
   ‚îú‚îÄ Boson fields (interaction carriers)
   ‚îÇ  ‚îú‚îÄ Gluons (strong interaction, SU(3) color)
   ‚îÇ  ‚îú‚îÄ Photon (electromagnetic, U(1))
   ‚îÇ  ‚îú‚îÄ W¬± and Z‚Å∞ (weak interaction)
   ‚îÇ  ‚îî‚îÄ Gravitational quantum (graviton, hypothetical)
   ‚îî‚îÄ Scalar field associated with electroweak symmetry breaking
      ‚îî‚îÄ Scalar boson (mass-generating excitation)

Composite structures
‚îî‚îÄ Atomic nucleus: protons + neutrons (held by residual strong force)
   ‚îú‚îÄ Atoms: nucleus + electron cloud (quantized orbitals)
   ‚îú‚îÄ Molecules: atoms bound via electromagnetic interaction
   ‚îî‚îÄ Condensed phases: solids, liquids, gases, plasmas, exotic matter
</pre>
    <p>‚ÄúMatter‚Äù typically denotes fermions and their composites. Gauge bosons (such as gluons) mediate interactions and are included for completeness.</p>
    <p>
      In the Standard Model, the fundamental fields can be written as a Lagrangian density \(\mathcal{L}_\text{SM}\) of the form
      \[
        \mathcal{L}_\text{SM} = -\frac{1}{4} \sum_{a} F_{\mu\nu}^a F^{a\,\mu\nu}
        + \sum_{f} \bar{\psi}_f\big(i\gamma^\mu D_\mu - m_f\big)\psi_f
        + (D_\mu \phi)^\dagger(D^\mu \phi) - V(\phi)
        + \mathcal{L}_\text{Yukawa},
      \]
      where
      \
        F_{\mu\nu}^a = \partial_\mu A_\nu^a - \partial_\nu A_\mu^a + g f^{abc} A_\mu^b A_\nu^c
      \\
      encodes the gauge bosons (gluons, \(W^\pm, Z^0\), photon), \(\psi_f\) are fermion fields (quarks and leptons), \(\phi\) is the Higgs scalar field, and
      \(D_\mu = \partial_\mu - i g A_\mu^a T^a\) is the gauge-covariant derivative.
    </p>
    <p>
      Color-charged quarks \(q\) interact via the SU(3) gauge field \(G_\mu^a\) with coupling constant \(g_s\), described by
      \[
        \mathcal{L}_\text{QCD} = \bar{q}\big(i\gamma^\mu D_\mu - m_q\big)q - \frac{1}{4} G_{\mu\nu}^a G^{a\,\mu\nu},
      \]
      where \(D_\mu = \partial_\mu - i g_s T^a G_\mu^a\) and \(G_{\mu\nu}^a\) has the same non-Abelian structure as \(F_{\mu\nu}^a\) above. Bound states such as protons and neutrons are color-singlet combinations of three quarks (baryons), while mesons are quark‚Äìantiquark pairs \(q \bar{q}\), consistent with overall color neutrality.
    </p>
    <p>
      Leptons (electron \(e\), muon \(\mu\), tau \(\tau\) and their neutrinos \(\nu_e, \nu_\mu, \nu_\tau\)) couple to the electroweak SU(2)\(_L\)\timesU(1)\(_Y\) gauge fields. After electroweak symmetry breaking, the Higgs field acquires a vacuum expectation value
      \[
        \langle \phi \rangle = \frac{1}{\sqrt{2}} \begin{pmatrix}0 \\ v \end{pmatrix}, \qquad v \approx 246~\text{GeV},
      \]
      which generates fermion and weak boson masses through Yukawa terms \(y_f \bar{\psi}_f \phi \psi_f\) and gauge interactions, while leaving the photon massless.
    </p>
    <p>
      Composite structures are organized hierarchically. A nucleus with \(Z\) protons and \(A-Z\) neutrons has baryon number \(B = A\) and charge \(Q = Z e\). An atom adds \(Z\) electrons, leading to a many-body Hamiltonian
      \[
        H = \sum_{i=1}^{Z} \bigg( -\frac{\hbar^2}{2m_e} \nabla_i^2 - \frac{Z e^2}{4\pi \varepsilon_0 r_i} \bigg)
          + \sum_{1 \le i < j \le Z} \frac{e^2}{4\pi \varepsilon_0 \lvert \mathbf{r}_i - \mathbf{r}_j \rvert}
          + H_\text{nucleus},
      \]
      whose eigenstates \(\Psi_n\) correspond to quantized orbitals and energy levels \(E_n\) solving
      \[
        H \Psi_n = E_n \Psi_n.
      \]
      Molecules and condensed phases arise when these atomic states combine via electromagnetic interactions into multi-atom bound states and extended many-body systems.
    </p>

    <section>
      <h2>Portfolio as a wave function: density matrices instead of variance‚Äìcovariance matrices</h2>
      <p>Below is a compact, code-adjacent sketch of the idea: in a quantum-flavored actuarial / MPT model, the classical variance‚Äìcovariance matrix \(\Sigma\) is upgraded to a density matrix \(\rho\), and a portfolio is treated as a wave function \(|\psi\rangle\). This mirrors what you might simulate with Stan, but in linear-algebra form.</p>

      <h3>Classical MPT / actuarial notation</h3>
      <pre><code>// n assets, vector of random returns R
// mean vector Œº, variance‚Äìcovariance matrix Œ£

E[R]   = Œº               // n√ó1
Cov(R) = Œ£               // n√ón (symmetric, PSD)

// portfolio weights (deterministic)
vector[n] w;
real R_p = dot_product(w, R);     // portfolio return

real mean_p   = dot_product(w, Œº);
real var_p    = quad_form(Œ£, w);  // w^T Œ£ w</code></pre>
      <p><em></em> \( \mathbb{E}[R] = \mu \), \( \operatorname{Cov}(R) = \Sigma \), \( R_p = w^\top R \), \( \mathbb{E}[R_p] = w^\top \mu \), \( \operatorname{Var}(R_p) = w^\top \Sigma w \).</p>

      <h3>Quantum-style upgrade</h3>
      <p>We now re-interpret these same objects in a Hilbert-space way:</p>
      <ul>
        <li>Basis states \(|e_i\rangle\): one-hot exposure to asset \(i\).</li>
        <li>Portfolio wave function \(|\psi\rangle = \sum_i \psi_i |e_i\rangle\) with \(\sum_i |\psi_i|^2 = 1\).</li>
        <li>Density matrix (pure state) \(\rho = |\psi\rangle\langle\psi|\).</li>
        <li>Return operator \(\hat R\) with components \(\hat R |e_i\rangle = R_i |e_i\rangle\) in the simplest diagonal case.</li>
      </ul>
      <p>In code-flavored pseudomath:</p>
      <pre><code>// amplitudes œà (complex allowed), normalized
complex psi[n];

// density matrix œÅ_ij = œà_i œà*_j
complex rho[n, n] = outer_product(psi, conj(psi));

// return operator RÃÇ (for illustration, take it diagonal)
real R_vals[n];                    // possible asset returns
complex R_op[n, n];

for (i in 1:n) {
  for (j in 1:n) {
    R_op[i,j] = (i == j) ? R_vals[i] : 0;
  }
}

// quantum expectation of portfolio return
complex mean_p_q = trace(rho * R_op);  // ‚âà classical w^T Œº
</code></pre>
// quantum expectation of portfolio return
complex mean_p_q = trace(rho * R_op); // &approx; classical w^T Œº</code></pre>
      <p>Mathematically,</p>
      <pre>œÅ = |œà><œà|
&lt;RÃÇ>_œà = &lt;œà| RÃÇ |œà> = Tr(œÅ RÃÇ)</pre>
      <p><em></em> \( \rho = |\psi\rangle\langle\psi| \), \( \langle \hat R \rangle_\psi = \langle \psi|\hat R|\psi\rangle = \operatorname{Tr}(\rho \hat R) \).</p>
      <p>If \(\hat R\) is diagonal in the \(|e_i\rangle\) basis and we ignore phases, \(|\psi_i|^2\) plays the same role as classical weights \(w_i\). But once off-diagonal elements are allowed, \(\rho\) carries richer cross-asset structure than \(\Sigma\) alone.</p>

      <h3>Stan-style simulation vs Schr√∂dinger-style evolution</h3>
      <p>Stan would typically simulate posterior draws of parameters \(\theta\) (e.g., drifts, vols, correlations) and then simulate returns:</p>
      <pre><code>// very schematic Stan pseudo-flow
for (m in 1:M) {
  Œ∏[m] ~ posterior(¬∑ | data);      // parameters: Œº[m], Œ£[m], etc.
  R[m] ~ mvnormal(Œº[m], Œ£[m]);     // draw returns
  R_p[m] = dot_product(w, R[m]);
}
// compute empirical mean/var/VaR of R_p from samples</code></pre>
      <p>In the wave-function view, instead of sampling many \(\theta\), we evolve the state itself under a Hamiltonian \(\hat H\) that encodes drift/volatility/market structure:</p>
      <pre><code>// time evolution of portfolio state œà_t
// i ‚Ñè d|œà_t>/dt = HÃÇ |œà_t>

psi_t+Œît ‚âà exp(-i Œît HÃÇ / ‚Ñè) * psi_t;

// at horizon T, density matrix œÅ_T = |œà_T><œà_T|
// expected payoff under operator Œ†ÃÇ
price_0 ‚âà discount * trace(œÅ_T * Œ†ÃÇ);</code></pre>
      <p>This is the code-level version of ‚Äúinstead of running Stan simulations over parameter space, we let the whole portfolio turn into a wave function and flow under \(\hat H\).‚Äù</p>

      <h3>Black‚ÄìScholes as the one-asset limit</h3>
      <p>For a single risky asset in Black‚ÄìScholes, under the risk-neutral measure we have</p>
      <pre>dS_t = r S_t dt + œÉ S_t dW_t</pre>
      <p>The price \(V(S,t)\) of a European claim satisfies</p>
      <pre>‚àÇV/‚àÇt + (1/2) œÉ^2 S^2 ‚àÇ^2V/‚àÇS^2 + r S ‚àÇV/‚àÇS - r V = 0</pre>
      <p>After changing variables \(x = \ln S\) and switching to forward time \(œÑ = T - t\), this maps to a heat equation which can be written in imaginary time as</p>
      <pre>‚àÇœÜ/‚àÇœÑ = (1/2) œÉ^2 ‚àÇ^2œÜ/‚àÇx^2 - V_eff(x) œÜ</pre>
      <p>Under a Wick rotation \(œÑ ‚Üí i t\), this resembles a Schr√∂dinger equation</p>
      <pre>i ‚Ñè ‚àÇœà/‚àÇt = HÃÇ œà</pre>
      <p>with \(\hat H\) containing a kinetic term (diffusion from \(œÉ\)) plus an effective potential. In this limit:</p>
      <ul>
        <li>Classical risk-neutral density \(f_{S_T}(s)\) ‚Üî \(|\psi(s,T)|^2\).</li>
        <li>Option price \(V_0\) ‚Üî expectation \(\langle \psi_T| \hat \Pi |\psi_T\rangle\).</li>
      </ul>
      <p>So Black‚ÄìScholes is already half-way to the quantum formalism: it evolves distributions through a linear PDE. The density-matrix formulation just generalizes this to multiple coupled assets and richer dependence than a single \(\Sigma\) can conveniently express.</p>
    </section>

    <section>
      
<table>
  <thead>
    <tr>
      <th>Rank</th>
      <th>System Name</th>
      <th>Developer</th>
      <th>Qubit Type</th>
      <th>Physical Qubits</th>
      <th>Key Performance Metrics</th>
      <th>Notable Achievements</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td class="rank">1</td>
      <td>System Model H2</td>
      <td>Quantinuum</td>
      <td>Trapped Ion</td>
      <td>32+ (scalable to 56)</td>
      <td>QV: 2¬≤‚Åµ (33,554,432); 2-qubit fidelity: 99.9% ("three 9s"); Logical qubits: Up to 12 entangled with 0.0011% error rate</td>
      <td>World's highest QV; 4√ó QV gain in 2025 alone; First chemistry sim combining QC, HPC, and AI; Outperforms all in stable, fault-tolerant ops.</td>
    </tr>
    <tr>
      <td class="rank">2</td>
      <td>Willow</td>
      <td>Google Quantum AI</td>
      <td>Superconducting</td>
      <td>105</td>
      <td>2-qubit fidelity: >99.9%; Performs RCS benchmark in <5 min (10¬≤‚Åµ years classically); Logical qubits: Demonstrated below-threshold error correction</td>
      <td>Quantum supremacy on practical tasks; Doubles coherence vs. physical qubits; Outpaces supercomputers by 10 septillion times on sampling.</td>
    </tr>
    <tr>
      <td class="rank">3</td>
      <td>Zuchongzhi 3.0</td>
      <td>USTC (China)</td>
      <td>Superconducting</td>
      <td>105</td>
      <td>1-qubit fidelity: 99.90%; 2-qubit fidelity: 99.62%; Task speed: Seconds (5.9B years classically)</td>
      <td>Rivals Willow in speed; Uses low-noise tantalum/niobium; 15√ó7 lattice for high connectivity; Major leap in raw performance.</td>
    </tr>
    <tr>
      <td class="rank">4</td>
      <td>Nighthawk</td>
      <td>IBM</td>
      <td>Superconducting</td>
      <td>120</td>
      <td>Up to 5,000 two-qubit gates; 2-qubit fidelity: ~99.5%; QV: >2¬≤‚Å∞ (est.); Tunable couplers: 218+</td>
      <td>Path to 2026 quantum advantage; 20% more couplers than Heron; Real-time error decoding in <480 ns; Utility-scale molecular sims with Fugaku supercomputer.</td>
    </tr>
    <tr>
      <td class="rank">5</td>
      <td>Forte Enterprise</td>
      <td>IonQ</td>
      <td>Trapped Ion</td>
      <td>36 (Tempo: 64 planned)</td>
      <td>2-qubit fidelity: 99.99% ("four 9s"); #AQ 36 (all-to-all connectivity); 20√ó performance gains in apps</td>
      <td>World-record fidelity for error correction; Efficient logical qubits with fewer physical ones; Used in drug discovery and finance modeling.</td>
    </tr>
    <tr>
      <td class="rank">6</td>
      <td>Ankaa-3</td>
      <td>Rigetti</td>
      <td>Superconducting</td>
      <td>84+ (100+ modular by end-2025)</td>
      <td>2-qubit fidelity: 99.5%; Nanosecond gate speeds; Real-time error correction on 84 qubits</td>
      <td>Fastest gate times (vs. microsecond rivals); Sold as QPUs to labs; Chiplet roadmap for utility-scale; 98% median fidelity in square lattice.</td>
    </tr>
    <tr>
      <td class="rank">7</td>
      <td>Neutral Atom Array</td>
      <td>QuEra Computing</td>
      <td>Neutral Atom</td>
      <td>3,000 (planned; current: 256)</td>
      <td>Logical qubits: 48 with 0.5% error (vs. IBM's 2.9%); High entanglement stability</td>
      <td>Fault-tolerant leader; Outperforms Heron in error rates; Scales to 10,000 qubits by 2026; Apps in logistics and materials science.</td>
    </tr>
    <tr>
      <td class="rank">8</td>
      <td>Majorana 1</td>
      <td>Microsoft (Azure Quantum)</td>
      <td>Topological</td>
      <td>~24 logical (scalable to 1M)</td>
      <td>Inherent low error rates; High-fidelity Majorana quasiparticles; Logical qubits: 12+ entangled</td>
      <td>First topological processor; Million-qubit potential; Integrates with Quantinuum/Atom for chemistry/AI; Below-threshold errors.</td>
    </tr>
    <tr>
      <td class="rank">9</td>
      <td>Advantage 2</td>
      <td>D-Wave</td>
      <td>Quantum Annealing</td>
      <td>7,440</td>
      <td>15-way connectivity; Quantum supremacy on real-world optimization</td>
      <td>Fastest for optimization (e.g., logistics); Not gate-based, but 3-month free trials via Leap; Beats classical on QUBO problems.</td>
    </tr>
    <tr>
      <td class="rank">10</td>
      <td>Kookaburra</td>
      <td>IBM</td>
      <td>Superconducting</td>
      <td>1,386 (multi-chip)</td>
      <td>Enhanced coherence; High gate fidelity (~99%); Part of Heron R2 upgrades</td>
      <td>Massive scale for 2025; Builds on Condor (1,121 qubits); Focus on error-corrected simulations; Quantum-centric supercomputing.</td>
    </tr>
  </tbody>
</table>

    </section>


    <section>
      <h2>Classical vs Quantum Computer: pseudo-code views</h2>
      <p>This section strips away hardware details and shows, in pseudo‚Äëcode, how a conventional laptop and a quantum processor ‚Äúfeel‚Äù different as machines.</p>

      <h3>Conventional computer (motherboard + CPU + RAM)</h3>
      <pre><code>// physical picture
// --------------------------------------------------
// motherboard: connects CPU, RAM, storage, peripherals
// CPU: executes instructions sequentially (with some parallelism)
// RAM: holds bits (0 or 1) for active programs

machine ClassicalComputer {
  Motherboard board;
  CPU         cpu;
  RAM         ram;
  Storage     disk;
}

// run a program
function run_classical(program P, input bits_in[]):
  // 1. load code and data into RAM
  ram.load(P.code)
  ram.load(bits_in)

  // 2. CPU executes instructions one by one
  while cpu.instruction_pointer not at END(P):
    instr = ram.fetch(cpu.instruction_pointer)
    cpu.execute(instr, ram)
    cpu.instruction_pointer++

  // 3. read out output bits from RAM
  bits_out = ram.read(P.output_region)
  return bits_out</code></pre>

      <h3>Quantum processor (QPU + classical control computer)</h3>
      <pre><code>// physical picture
// --------------------------------------------------
// classical control computer: compiles code, sends pulses
// quantum processing unit (QPU): array of qubits on a chip
// cryostat: keeps QPU near absolute zero

machine QuantumComputer {
  ClassicalControl ctrl;     // compiler, schedulers
  QuantumProcessingUnit qpu; // qubits + control lines
}

// high-level quantum run
function run_quantum(circuit C, classical_input bits_in[]):
  // 1. classical pre-processing
  //    e.g., encode bits_in into initial qubit states
  compiled_pulses = ctrl.compile(C, bits_in)

  // 2. upload pulse schedule to QPU
  qpu.load(compiled_pulses)

  // 3. apply quantum operations (unitaries)
  qpu.apply_pulses()
  // internally, each gate is a unitary U on |œà>:
  //    |œà_new> = U |œà_old>

  // 4. measure qubits
  measurement_record = qpu.measure_all() // collapses |œà> ‚Üí classical bits

  // 5. classical post-processing
  result = ctrl.post_process(measurement_record)
  return result</code></pre>

      <p>Conceptually:</p>
      <ul>
        <li>The <strong>classical CPU</strong> walks through a list of instructions, flipping bits in RAM.</li>
        <li>The <strong>QPU</strong> evolves a joint quantum state \(|\psi\rangle\) of many qubits by applying gates (unitaries), then collapses that state to classical bits via measurement.</li>
      </ul>

      <h3>Same abstract computation, two execution models</h3>
      <p>Imagine we want to compute the parity (even/odd) of \(N\) bits.</p>

      <h4>Classical laptop parity</h4>
      <pre><code>function parity_classical(bits[]):
  acc = 0
  for b in bits:
    acc = acc XOR b
  return acc  // 0 = even, 1 = odd</code></pre>

      <h4>Quantum parity sketch (conceptual)</h4>
      <pre><code>function parity_quantum(bits[]):
  // 1. encode bits into computational basis states
  //    |b_1 b_2 ... b_N>
  |œà> = |b_1 b_2 ... b_N>

  // 2. use a circuit of CNOTs to copy global parity into an ancilla qubit
  //    |œà, 0>  ‚Üí  |œà, parity(bits)>
  for i in 1..N:
    CNOT(control = qubit_i, target = ancilla)

  // 3. measure only the ancilla qubit
  result = measure(ancilla)
  return result  // 0 = even, 1 = odd</code></pre>
      <p>On such a small task, the quantum route is not ‚Äúbetter‚Äù than the classical one‚Äîit is just a different physical implementation of the same logical function. Real quantum advantage typically appears in problems that exploit superposition and interference over huge state spaces.</p>
      
      <details class="qc-deepdive">
        <summary>Deep dive: complexity classes BPP vs BQP</summary>
        <div>
          <p>If you like big‚Äëpicture theory, the usual cartoon is:</p>
          <ul>
            <li><strong>BPP</strong> (‚Äúbounded‚Äëerror probabilistic polynomial time‚Äù): problems efficiently solvable by a classical computer that can flip random bits, with error probability \(< 1/3\) (or any fixed constant &lt; 1/2).</li>
            <li><strong>BQP</strong> (‚Äúbounded‚Äëerror quantum polynomial time‚Äù): problems efficiently solvable by a quantum computer, again with error probability \(< 1/3\).</li>
          </ul>
          <p>Formally, a language \(L\) is in BQP if there is a family of quantum circuits \(\{C_n\}\) of size polynomial in \(n\) such that for all inputs \(x\) of length \(n\):</p>
          <ul>
            <li>If \(x \in L\), then \(\Pr[C_n(x) = 1] \ge 2/3\).</li>
            <li>If \(x \notin L\), then \(\Pr[C_n(x) = 1] \le 1/3\).</li>
          </ul>
          <p>We know that \(\text{BPP} \subseteq \text{BQP}\) (quantum can simulate classical randomness), but we do not know whether \(\text{BPP} = \text{BQP}\) or \(\text{BPP} \subsetneq \text{BQP}\). Evidence from Shor‚Äôs algorithm and other candidates strongly suggests that \(\text{BQP}\) is strictly more powerful than \(\text{BPP}\) for some natural problems (like factoring large integers), but there is no proof yet.</p>
        </div>
      </details>
    </section>

    <section>
      <h2>Hardware analogy table: consumer laptop vs quantum processor</h2>
      <p>The numbers below are intentionally rounded, order‚Äëof‚Äëmagnitude style, to give intuition. Real devices vary wildly; treat these as cartoon benchmarks, not spec sheets.</p>

      <table border="1" cellpadding="4" cellspacing="0">
        <thead>
          <tr>
            <th>Device</th>
            <th>Rough scale</th>
            <th>Operation type</th>
            <th>Throughput (back‚Äëof‚Äëenvelope)</th>
            <th>Notes</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Consumer laptop CPU (1 core)</td>
            <td>~3 GHz clock</td>
            <td>Classical bit ops</td>
            <td>~3√ó10<sup>9</sup> simple ops/s</td>
            <td>One scalar instruction stream; vector units add more parallelism.</td>
          </tr>
          <tr>
            <td>Consumer laptop (8 cores, SIMD)</td>
            <td>8 cores √ó 3 GHz √ó 128‚Äëbit SIMD</td>
            <td>Classical bit/word ops</td>
            <td>~10<sup>11</sup>‚Äì10<sup>12</sup> basic ops/s</td>
            <td>Depends heavily on workload and vectorization.</td>
          </tr>
          <tr>
            <td>Mid‚Äërange GPU in a laptop</td>
            <td>~10<sup>3</sup>‚Äì10<sup>4</sup> cores</td>
            <td>Classical float ops</td>
            <td>~10<sup>12</sup>‚Äì10<sup>13</sup> FLOP/s peak</td>
            <td>Great for dense linear algebra and ML training.</td>
          </tr>
          <tr>
            <td>Small noisy quantum processor</td>
            <td>~50‚Äì100 physical qubits</td>
            <td>Quantum gates on 2<sup>N</sup>-dim state</td>
            <td>~10<sup>3</sup>‚Äì10<sup>4</sup> 2‚Äëqubit gates per run before noise</td>
            <td>Each gate acts on amplitudes of 2<sup>N</sup> basis states in superposition.</td>
          </tr>
          <tr>
            <td>Hypothetical fault‚Äëtolerant QPU</td>
            <td>~10<sup>6</sup> physical qubits ‚Üí 10<sup>3</sup> logical</td>
            <td>Error‚Äëcorrected quantum circuits</td>
            <td>~10<sup>9</sup>‚Äì10<sup>12</sup> logical gates over long algorithms</td>
            <td>Aimed at large chemistry, optimization, or cryptographic tasks.</td>
          </tr>
        </tbody>
      </table>

      <h3>"How many laptops equal one quantum processor?" (cartoon answers)</h3>
      <p>The trick is: you cannot fairly compare them just by counting operations per second, because a quantum gate on \(N\) qubits simultaneously transforms amplitudes across \(2^N\) basis states. Still, you can get a feeling by asking:</p>

      <h4>Example 1: simulating 30 qubits on laptops</h4>
      <ul>
        <li>State vector size: \(2^{30} \approx 10^9\) complex amplitudes.</li>
        <li>One layer of single‚Äëqubit gates might touch all \(10^9\) amplitudes.</li>
        <li>A single good laptop GPU at ~10<sup>12</sup> FLOP/s can simulate ~10<sup>3</sup> such layers per second <em>in theory</em>, but memory bandwidth and overhead reduce this a lot.</li>
      </ul>
      <p>A small physical QPU with 30‚Äì40 qubits applies the same logical layer <em>directly in hardware</em>; it is as if you had a cluster of hundreds to thousands of laptops working together to update all amplitudes every gate.</p>

      <h4>Example 2: 50‚Äëqubit state</h4>
      <ul>
        <li>State vector size: \(2^{50} \approx 10^{15}\) complex amplitudes.</li>
        <li>Storing this naively (16 bytes per complex) needs ~16 petabytes of RAM.</li>
        <li>Even a supercomputer cluster of millions of consumer‚Äëclass laptops would struggle to hold and update this in full generality.</li>
      </ul>
      <p>So for <strong>generic</strong> 50‚Äëqubit circuits, one real QPU is morally comparable to an enormous classical cluster. For <strong>structured</strong> problems, clever classical algorithms can do much better‚Äîthat‚Äôs why the ‚Äúhow many laptops‚Äù question has no single honest number.</p>

      <h3>Very rough equivalence table (for mental models only)</h3>
      <table border="1" cellpadding="4" cellspacing="0">
        <thead>
          <tr>
            <th>Quantum device (noisy)</th>
            <th>State size 2<sup>N</sup></th>
            <th>Naive RAM to store state</th>
            <th>Approx. # of 16 GB laptops for RAM only</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>20‚Äëqubit QPU</td>
            <td>~10<sup>6</sup></td>
            <td>~16 MB</td>
            <td>&lt; 1 laptop (fits easily)</td>
          </tr>
          <tr>
            <td>30‚Äëqubit QPU</td>
            <td>~10<sup>9</sup></td>
            <td>~16 GB</td>
            <td>~1 laptop (RAM is tight but possible)</td>
          </tr>
          <tr>
            <td>40‚Äëqubit QPU</td>
            <td>~10<sup>12</sup></td>
            <td>~16 TB</td>
            <td>~1000 laptops (each 16 GB)</td>
          </tr>
          <tr>
            <td>50‚Äëqubit QPU</td>
            <td>~10<sup>15</sup></td>
            <td>~16 PB</td>
            <td>~1,000,000 laptops (each 16 GB)</td>
          </tr>
        </tbody>
      </table>
      <p>This table only matches <em>memory</em> capacity, not speed. But it gives a rough intuition: once you pass ~40‚Äì50 entangled qubits in a generic circuit, brute‚Äëforce classical simulation starts looking like ‚Äúyou‚Äôd need an absurd number of consumer laptops.‚Äù</p>
    </section>

    <section>
      <h2>SHA-256 password hashing examples</h2>
      <p>The table below shows a few simple example passwords and their corresponding SHA-256 hash values. These are illustrative only; never hard‚Äëcode real passwords or reuse simple patterns like these in production.</p>
      <table border="1" cellpadding="4" cellspacing="0">
        <thead>
          <tr>
            <th>Example password</th>
            <th>SHA-256 hash (hex)</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>password</td>
            <td>5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8</td>
          </tr>
          <tr>
            <td>123456</td>
            <td>8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92</td>
          </tr>
          <tr>
            <td>correcthorsebatterystaple</td>
            <td>cbe6beb26479b568e5f15b50217c6c83c0ee051dc4e522b9840d8e291d6aaf46</td>
          </tr>
          <tr>
            <td>QuantumR0cks!</td>
            <td>a7c2a1b4b785bb7b39d6b26bafdc6f919aa0cc47a18eb2f6559bf0369a671a7a</td>
          </tr>
        </tbody>
      </table>
      <p style="margin-top:0.75rem; font-size:0.9em;">
        Hashes above were computed with standard SHA-256; you can reproduce them using tools like <code>sha256sum</code>, <code>openssl dgst -sha256</code>, Python‚Äôs <code>hashlib.sha256</code>, or any reputable online hash calculator.
      </p>
    </section>

    <!-- BEGIN: Added password cracking / MFA table and explanation -->
    <section>
      <h2>How long would it take to crack these passwords?</h2>
      <p>The table below uses deliberately rough, order‚Äëof‚Äëmagnitude estimates to show how different passwords fare against brute‚Äëforce search on classical hardware and on a future, optimistic quantum attacker using Grover-style speedups. The point is not the exact numbers, but the contrast between weak and strong secrets‚Äîand why multi‚Äëfactor authentication (MFA) is so valuable.</p>

      <style>
        
    table {
      width: 100%;
      max-width: 1400px;
      border-collapse: separate;
      border-spacing: 0;
      border-radius: 12px;
      overflow: hidden;
      box-shadow: 0 10px 30px rgba(0,0,0,0.15);
      background: #4682b4; /* steelblue */
    }
    thead th {
      background: #2c5d80;
      color: white;
      padding: 16px 12px;
      text-align: left;
      font-weight: 600;
      font-size: 1rem;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    tbody tr:nth-child(odd) {
      background: #5a9bd4;
      color: white;
    }
    tbody tr:nth-child(even) {
      background: #3a7bb8;
      color: white;
    }
    tbody tr:hover {
      background: #6ab6f0 !important;
      transition: background 0.25s ease;
    }
    td, th {
      padding: 14px 12px;
      border-right: 1px solid rgba(255,255,255,0.15);
    }
    td:last-child, th:last-child {
      border-right: none;
    }
    tr:last-child td {
      border-bottom: none;
    }
    .rank {
      font-weight: bold;
      font-size: 1.2rem;
      text-align: center;
    }
    @media (max-width: 1024px) {
      table { font-size: 0.9rem; }
      th, td { padding: 10px 8px; }
    }

        .password-crack-table-wrapper {
          margin: 1.5rem 0;
          overflow-x: auto;
        }
        table.password-crack-table {
          border-collapse: collapse;
          width: 100%;
          max-width: 100%;
          font-size: 0.9rem;
          background: #0b1020;
          color: #f5f7ff;
          border-radius: 8px;
          overflow: hidden;
          box-shadow: 0 0 0 1px rgba(255,255,255,0.04), 0 10px 30px rgba(0,0,0,0.4);
        }
        .password-crack-table thead {
          background: linear-gradient(90deg, #182848, #4b6cb7);
        }
        .password-crack-table th,
        .password-crack-table td {
          padding: 0.6rem 0.75rem;
          border: 1px solid rgba(255,255,255,0.07);
          vertical-align: top;
        }
        .password-crack-table th {
          text-align: left;
          font-weight: 600;
          white-space: nowrap;
        }
        .password-crack-table tbody tr:nth-child(odd) {
          background: rgba(255,255,255,0.02);
        }
        .password-crack-table tbody tr:nth-child(even) {
          background: rgba(255,255,255,0.06);
        }
        .pw-weak {
          background: rgba(255, 99, 71, 0.12);
        }
        .pw-strong {
          background: rgba(46, 204, 113, 0.12);
        }
        .pw-label {
          font-family: monospace;
          font-weight: 600;
        }
        .pw-note {
          font-size: 0.8rem;
          color: #c9d2ff;
        }
        .mfa-callout {
          margin-top: 1.5rem;
          padding: 1rem 1.1rem;
          border-radius: 8px;
          background: rgba(0, 173, 181, 0.06);
          border: 1px solid rgba(0, 173, 181, 0.6);
        }
        .mfa-callout h3 {
          margin-top: 0;
          margin-bottom: 0.4rem;
        }
        .mfa-callout ul {
          margin: 0.4rem 0 0.2rem 1.15rem;
        }
        .mfa-callout li {
          margin-bottom: 0.2rem;
        }
      </style>

      <div class="password-crack-table-wrapper">
        <table class="password-crack-table">
          <thead>
            <tr>
              <th>Password<br><span style="font-size:0.75rem; opacity:0.85;">(example only)</span></th>
              <th>SHA‚Äë256 hash (first 16 hex chars)</th>
              <th>Approx. search space</th>
              <th>Brute‚Äëforce time ‚Äì classical attacker<br><span style="font-size:0.75rem; opacity:0.85;">(10<sup>12</sup> guesses/sec)</span></th>
              <th>Brute‚Äëforce time ‚Äì quantum attacker<br><span style="font-size:0.75rem; opacity:0.85;">(10<sup>18</sup> "effective" guesses/sec with Grover)</span></th>
            </tr>
          </thead>
          <tbody>
            <tr class="pw-weak">
              <td>
                <div class="pw-label">123456</div>
                <div class="pw-note">6 digits, only numbers</div>
              </td>
              <td>8d969eef6ecad3c2‚Ä¶</td>
              <td>10<sup>6</sup> ‚âà 1,000,000</td>
              <td>‚âà 10<sup>-6</sup> s (microseconds)</td>
              <td>Effectively instant</td>
            </tr>
            <tr class="pw-weak">
              <td>
                <div class="pw-label">password</div>
                <div class="pw-note">8 lower‚Äëcase letters</div>
              </td>
              <td>5e884898da280471‚Ä¶</td>
              <td>26<sup>8</sup> ‚âà 2√ó10<sup>11</sup></td>
              <td>‚âà 200 seconds (minutes)</td>
              <td>Grover over full space makes it even easier ‚Äì effectively trivial</td>
            </tr>
            <tr>
              <td>
                <div class="pw-label">correcthorsebatterystaple</div>
                <div class="pw-note">~25 lower‚Äëcase; if chosen from 10<sup>4</sup> words<br>and 4‚Äëword combos ‚áí ~10<sup>16</sup> possibilities</div>
              </td>
              <td>cbe6beb26479b568‚Ä¶</td>
              <td>‚âà 10<sup>16</sup> (for a simple wordlist model)</td>
              <td>‚âà 10<sup>4</sup> s ‚âà a few hours<br>with a strong classical rig and very good wordlist</td>
              <td>Grover‚Äëstyle speedup over 10<sup>16</sup> gives ‚àö10<sup>16</sup>=10<sup>8</sup> steps.<br>At 10<sup>18</sup> "effective" ops/s ‚áí ~10<sup>-10</sup> s, but this<br>ignores huge practical overheads. Still: quantum helps.</td>
            </tr>
            <tr class="pw-strong">
              <td>
                <div class="pw-label">S7q!vP9$Lm@2</div>
                <div class="pw-note">12 chars, ~72‚Äëchar alphabet<br>(upper/lower/digits/symbols)</div>
              </td>
              <td>(example) 4f9c2b1a7d8e6c5b‚Ä¶</td>
              <td>‚âà 72<sup>12</sup> ‚âà 4√ó10<sup>22</sup></td>
              <td>4√ó10<sup>10</sup> seconds ‚âà 1,200+ years</td>
              <td>Grover reduces work to ‚àö4√ó10<sup>22</sup> ‚âà 2√ó10<sup>11</sup> steps.<br>At 10<sup>18</sup>/s ‚áí ‚âà 2√ó10<sup>-7</sup> s in the toy model,<br>but building such a fault‚Äëtolerant quantum machine for real‚Äëworld
hash cracking is far beyond current tech.</td>
            </tr>
          </tbody>
        </table>
      </div>

      <p style="font-size:0.85rem; opacity:0.9; margin-top:0.4rem;">
        Assumptions are deliberately aggressive in favor of the attacker and
        ignore I/O, memory, and protocol defenses; they‚Äôre meant as back‚Äëof‚Äëthe‚Äëenvelope
        illustrations, not operational guarantees. Also, SHA‚Äë256 is used here in
        isolation; real systems should wrap it in slow, memory‚Äëhard KDFs such as
        bcrypt, scrypt, or Argon2.
      </p>


    </section>
    <!-- END: Added password cracking / MFA table and explanation -->

    <!-- ... continue with all your tables, SHA-256 examples, cracking table, MFA callout, etc. ... -->

  </div>

  <!-- Footer -->
  <footer>
    <p>Are Tech Talks your Vibe?</p>
    <a href="https://www.youtube.com/@predictiveanalyst?sub_confirmation=1" class="subscribe-btn" target="_blank">
      Subscribe on YouTube
    </a>
    <p style="margin-top:40px;color:#888;">
      ¬© 2025 Predictive Analyst ‚Ä¢ <a href="https://predictiveinsightsai.com/" style="color:var(--accent);">predictiveinsightsai.com</a>
    </p>
  </footer>

</body>
</html>